"""
Executive-level Feedback Intelligence Report Generator.

Generates reports from the perspective of a Senior Product Analyst,
Game Monetization Strategist, and QA Lead. Focuses on business impact,
player pain, retention risks, and revenue risks â€” not just frequency tables.
"""

from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from .aggregator import AggregatedInsights
from .config import REPORTS_JSON_DIR, REPORTS_MARKDOWN_DIR
from .context_loader import GameFeatureContext
from .input_handler import FeedbackAnalysisInput
from .logger import get_logger
from .utils import get_timestamp, sanitize_filename, save_json, save_markdown


logger = get_logger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION BUILDERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _header(title: str, level: int = 2) -> str:
    prefix = "#" * level
    return f"\n{prefix} {title}\n"


def _divider() -> str:
    return "\n---\n"


def _build_executive_brief(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]],
    input_params: FeedbackAnalysisInput
) -> str:
    """Top-level signal overview ranked by business impact."""
    total = insights.total_tickets

    # Sentiment breakdown
    sent = insights.sentiment_breakdown
    neg_pct = round(sent.get('Negative', 0) / total * 100, 1) if total else 0
    pos_pct = round(sent.get('Positive', 0) / total * 100, 1) if total else 0

    # Business risk breakdown
    risks = Counter(c.get('business_risk') for c in classifications if c.get('business_risk'))

    # Critical severity count
    critical = sum(1 for c in classifications if c.get('sentiment_severity') == 'Critical')

    # Churn threats
    churn_threats = sum(1 for c in classifications if 'Churn' in (c.get('intent', '') or ''))

    # Payer signals
    payers = sum(1 for c in classifications if c.get('player_type_signal') == 'Payer')

    lines = [
        _header("ðŸ“‹ Feedback Intelligence Report", 1),
        f"> **Game:** {input_params.game_name} | **Platform:** {input_params.os} | "
        f"**Period:** {input_params.start_date} â†’ {input_params.end_date} | "
        f"**Tickets Analyzed:** {total} | **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        _header("ðŸš¨ Executive Brief", 2),
        "",
        f"| Signal | Value | Risk Level |",
        f"|--------|-------|------------|",
        f"| Overall Negative Sentiment | {neg_pct}% | {'ðŸ”´ Critical' if neg_pct > 60 else 'ðŸŸ¡ High' if neg_pct > 40 else 'ðŸŸ¢ Moderate'} |",
        f"| Overall Positive Sentiment | {pos_pct}% | {'ðŸŸ¢ Healthy' if pos_pct > 40 else 'ðŸŸ¡ Watch' if pos_pct > 20 else 'ðŸ”´ Alarming'} |",
        f"| Critical Severity Tickets | {critical} ({round(critical/total*100,1) if total else 0}%) | {'ðŸ”´ Act Now' if critical > 5 else 'ðŸŸ¡ Monitor'} |",
        f"| Churn Threat Signals | {churn_threats} | {'ðŸ”´ High' if churn_threats > 3 else 'ðŸŸ¡ Medium'} |",
        f"| Payer-Identified Complaints | {payers} | {'ðŸ”´ Revenue Risk' if payers > 0 else 'ðŸŸ¢ Low'} |",
    ]

    for risk, count in risks.most_common(4):
        if risk:
            pct = round(count / total * 100, 1)
            lines.append(f"| {risk} Risk Tickets | {count} ({pct}%) | {'ðŸ”´' if pct > 20 else 'ðŸŸ¡'} |")

    lines.append("")
    lines.append("> **Bottom Line:** " + _generate_bottom_line(neg_pct, critical, churn_threats, payers, total))
    lines.append("")

    return "\n".join(lines)


def _generate_bottom_line(neg_pct, critical, churn_threats, payers, total) -> str:
    """Generate a sharp, analytical executive bottom line."""
    if neg_pct > 65 and critical > 5:
        return (f"Feedback is in a **danger zone** â€” {neg_pct}% negative with {critical} critical severity tickets. "
                f"Immediate product intervention required before this impacts store ratings.")
    elif neg_pct > 40 and payers > 0:
        return (f"Monetization trust is at risk. {payers} payer-identified complaints detected. "
                f"Revenue churn risk is elevated â€” prioritize payer pain resolution above all else.")
    elif churn_threats > 3:
        return (f"{churn_threats} players explicitly signaled intent to leave or warn others. "
                f"Retention is actively eroding â€” focus on friction reduction immediately.")
    elif neg_pct < 30:
        return (f"Feedback is relatively healthy at {neg_pct}% negative, but do not become complacent â€” "
                f"monitor the identified friction points before they compound.")
    else:
        return (f"{neg_pct}% negative sentiment across {total} tickets. "
                f"Several actionable pain points identified â€” prioritize by business impact, not frequency.")


def _build_pain_points(
    classifications: List[Dict[str, Any]],
    insights: AggregatedInsights
) -> str:
    """Deep-dive into real player pain points ranked by business impact."""

    lines = [_header("ðŸ”¥ Major Player Pain Points", 2)]
    lines.append("> Ranked by **business impact**, not frequency. Signal separated from noise.\n")

    # Group by (category, subcategory) and sort by business risk severity
    risk_order = {'Revenue': 0, 'Trust': 1, 'Retention': 2, 'Rating': 3, None: 4}

    groups = defaultdict(list)
    for c in classifications:
        if c.get('sentiment') in ['Negative', 'Mixed']:
            key = (c.get('category', 'Other'), c.get('subcategory', 'General'))
            groups[key].append(c)

    # Sort by business risk then by count
    sorted_groups = sorted(
        groups.items(),
        key=lambda x: (
            min(risk_order.get(c.get('business_risk'), 4) for c in x[1]),
            -len(x[1])
        )
    )

    for rank, ((category, subcategory), tickets) in enumerate(sorted_groups[:8], 1):
        count = len(tickets)
        total = len(classifications)
        pct = round(count / total * 100, 1)

        # Severity breakdown
        severities = Counter(t.get('sentiment_severity') for t in tickets)
        critical_count = severities.get('Critical', 0)
        is_100_neg = all(t.get('sentiment') == 'Negative' for t in tickets)

        # Pain signals
        pain_signals = list({t.get('short_summary') for t in tickets if t.get('short_summary')})[:3]

        # Root causes
        root_causes = list({t.get('root_cause') for t in tickets if t.get('root_cause')})[:2]

        # Suggested solutions
        solutions = list({t.get('player_suggested_solution') for t in tickets if t.get('player_suggested_solution')})[:2]

        # Business risks
        business_risks = list({t.get('business_risk') for t in tickets if t.get('business_risk')})

        # Pain types
        pain_types = list({t.get('pain_type') for t in tickets if t.get('pain_type')})

        # Payer count
        payer_count = sum(1 for t in tickets if t.get('player_type_signal') == 'Payer')

        severity_emoji = "ðŸ”´" if critical_count > 0 or is_100_neg else "ðŸŸ¡" if pct > 10 else "ðŸŸ¢"

        lines.extend([
            _header(f"{rank}. {severity_emoji} {category} â€” {subcategory}", 3),
            "",
            f"**Affected Tickets:** {count} ({pct}%) {'| âš ï¸ 100% Negative Cluster' if is_100_neg else ''}  ",
            f"**Critical Severity:** {critical_count} tickets  ",
            f"**Pain Type:** {', '.join(pain_types) if pain_types else 'N/A'}  ",
            f"**Business Risk:** {', '.join(business_risks) if business_risks else 'N/A'}  ",
            f"**Payer Complaints:** {payer_count}  ",
            "",
            "**Player Pain Signals:**",
        ])

        for signal in pain_signals:
            lines.append(f"- *\"{signal}\"*")

        if root_causes:
            lines.append("\n**Probable Root Cause:**")
            for cause in root_causes:
                lines.append(f"- {cause}")

        if solutions:
            lines.append("\n**Player-Suggested Solutions (explicit/implicit):**")
            for sol in solutions:
                lines.append(f"- {sol}")

        # Recommend fixes based on category
        lines.append("\n**Recommended Actions:**")
        lines.extend(_get_recommendations(category, subcategory, business_risks))

        lines.append("")

    return "\n".join(lines)


def _get_recommendations(category: str, subcategory: str, business_risks: List[str]) -> List[str]:
    """Generate product, UX, and engineering recommendations."""
    recs = []
    cat_lower = category.lower()
    sub_lower = subcategory.lower()

    if 'monetization' in cat_lower or 'revenue' in str(business_risks):
        recs.extend([
            "- ðŸ·ï¸ **Product:** Review pricing, value perception, and IAP messaging â€” trust erosion is harder to recover than churn",
            "- ðŸŽ¨ **UX:** Add clear value indicators before purchase prompts; reduce surprise costs",
            "- âš™ï¸ **Engineering:** Ensure purchase confirmation flows are error-free; audit failed transaction rates"
        ])
    elif 'trust' in str(business_risks) or 'trust' in cat_lower:
        recs.extend([
            "- ðŸ·ï¸ **Product:** Issue transparent communication to players about this issue",
            "- ðŸŽ¨ **UX:** Add in-app notification or progress confirmation to rebuild trust",
            "- âš™ï¸ **Engineering:** Implement redundant save/sync with visible confirmation states"
        ])
    elif 'balance' in cat_lower or 'difficulty' in sub_lower:
        recs.extend([
            "- ðŸ·ï¸ **Product:** Review difficulty curve analytics â€” identify specific levels with abnormal drop-off rates",
            "- ðŸŽ¨ **UX:** Consider optional difficulty scaling or better hint system visibility",
            "- âš™ï¸ **Engineering:** Instrument level completion rates, hint usage, and quit points per level"
        ])
    elif 'bug' in cat_lower or 'technical' in cat_lower:
        recs.extend([
            "- ðŸ·ï¸ **Product:** Triage by device/OS segment to understand blast radius",
            "- ðŸŽ¨ **UX:** Add graceful error states and recovery flows",
            "- âš™ï¸ **Engineering:** Prioritize crash reports; check if reproducible on latest builds"
        ])
    else:
        recs.extend([
            "- ðŸ·ï¸ **Product:** Investigate player journey at this friction point with analytics",
            "- ðŸŽ¨ **UX:** Reduce cognitive load and improve feedback clarity",
            "- âš™ï¸ **Engineering:** Instrument the affected flow to capture failure signals"
        ])

    return recs


def _build_positive_drivers(
    classifications: List[Dict[str, Any]],
    insights: AggregatedInsights
) -> str:
    """Analyze what players love and how to scale it safely."""

    pos_tickets = [c for c in classifications if c.get('sentiment') == 'Positive']

    if not pos_tickets:
        return _header("ðŸ’š Positive Drivers", 2) + "\n> No strong positive signals detected in this dataset.\n"

    lines = [
        _header("ðŸ’š Positive Drivers & Monetization Opportunities", 2),
        "> What players love, why it works emotionally, and how to scale safely.\n"
    ]

    # Group positive signals by feature
    feature_groups = defaultdict(list)
    for c in pos_tickets:
        feature = c.get('related_feature') or 'General'
        feature_groups[feature].append(c)

    for feature, tickets in sorted(feature_groups.items(), key=lambda x: -len(x[1]))[:5]:
        count = len(tickets)
        pct = round(count / len(classifications) * 100, 1)
        summaries = list({t.get('short_summary') for t in tickets if t.get('short_summary')})[:2]

        payer_love = sum(1 for t in tickets if t.get('player_type_signal') == 'Payer')

        lines.extend([
            f"### âœ… {feature} ({count} positive mentions, {pct}%)",
            "",
        ])
        for s in summaries:
            lines.append(f"- *\"{s}\"*")

        lines.extend([
            "",
            f"**Why it works:** Players express genuine satisfaction â€” this is a stickiness signal.",
            f"**Payer love count:** {payer_love} (monetizable engagement)",
            f"**Scale opportunity:** Consider extending this feature, building seasonal variants, or offering premium expansions.",
            ""
        ])

    return "\n".join(lines)


def _build_hidden_patterns(
    classifications: List[Dict[str, Any]],
    insights: AggregatedInsights
) -> str:
    """Detect hidden patterns, UX gaps, and systemic issues."""

    lines = [
        _header("ðŸ” Hidden Patterns & Systemic Issues", 2),
        "> Insights not visible from category counts alone.\n"
    ]

    # 1. 100% negative clusters
    groups = defaultdict(list)
    for c in classifications:
        key = c.get('subcategory', 'Unknown')
        groups[key].append(c)

    hundred_pct_neg = [
        (k, v) for k, v in groups.items()
        if len(v) >= 3 and all(t.get('sentiment') == 'Negative' for t in v)
    ]

    if hundred_pct_neg:
        lines.append("### ðŸš¨ 100% Negative Clusters (Zero Satisfaction)")
        lines.append("")
        for sub, tickets in sorted(hundred_pct_neg, key=lambda x: -len(x[1])):
            lines.append(f"- **{sub}**: {len(tickets)} tickets â€” ALL negative. No positive signal at all. This is a systemic issue, not edge case feedback.")
        lines.append("")

    # 2. Communication gap signals
    comms_gap = [c for c in classifications if c.get('pain_type') in ['Trust', 'Emotional']
                 and c.get('business_risk') in ['Trust', 'Rating']]
    if comms_gap:
        lines.extend([
            "### ðŸ“¢ Communication Gaps",
            "",
            f"{len(comms_gap)} tickets indicate players feel **uninformed or misled** â€” a sign of poor in-game communication or unclear UX.",
            "Root fix: proactive in-app messaging, clearer feature explanations, and expectation-setting.",
            ""
        ])

    # 3. Overuse of generic categories
    generic = sum(1 for c in classifications if c.get('category') == 'Other')
    if generic > len(classifications) * 0.1:
        lines.extend([
            "### âš ï¸ Feedback Intelligence System Issue",
            "",
            f"{generic} tickets ({round(generic/len(classifications)*100,1)}%) classified as 'Other' â€” "
            "this suggests the AI categorization needs richer taxonomy or more context.",
            "**Recommendation:** Expand category definitions or add game-specific categories to the prompt.",
            ""
        ])

    # 4. Payer vs non-payer signal
    payers = [c for c in classifications if c.get('player_type_signal') == 'Payer']
    non_payers = [c for c in classifications if c.get('player_type_signal') == 'Non-Payer']
    if payers:
        payer_neg = sum(1 for p in payers if p.get('sentiment') == 'Negative')
        lines.extend([
            "### ðŸ’³ Payer vs Non-Payer Signal",
            "",
            f"- **Payer-identified tickets:** {len(payers)} | Negative: {payer_neg} ({round(payer_neg/len(payers)*100,1) if payers else 0}%)",
            f"- **Non-payer tickets:** {len(non_payers)}",
            "",
            f"> {'ðŸ”´ **Payer complaints are revenue-critical.** Address these first.' if payer_neg > 0 else 'ðŸŸ¢ Payer signals look stable.'}",
            ""
        ])

    return "\n".join(lines)


def _build_strategic_recommendations(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]]
) -> str:
    """Strategic recommendations in sprint / short / long-term tiers."""

    lines = [
        _header("ðŸŽ¯ Strategic Recommendations", 2),
        "> Prioritized by business impact, not complaint volume.\n"
    ]

    # Immediate
    critical_issues = [c for c in classifications if c.get('sentiment_severity') == 'Critical']
    churn_signals = [c for c in classifications if 'Churn' in (c.get('intent') or '')]
    revenue_risks = [c for c in classifications if c.get('business_risk') == 'Revenue']

    lines.extend([
        "### ðŸš¨ Immediate (This Sprint)",
        "",
        f"- **Fix critical-severity issues first** â€” {len(critical_issues)} tickets flagged as Critical. "
        "These players are on the edge of churning or leaving 1-star reviews.",
    ])
    if churn_signals:
        lines.append(f"- **Address churn-threat signals** â€” {len(churn_signals)} players explicitly signaled leaving. "
                     "Reach out via CS or in-app if possible.")
    if revenue_risks:
        lines.append(f"- **Audit revenue risk flows** â€” {len(revenue_risks)} tickets flag monetization friction. "
                     "Run conversion funnel audit this week.")
    lines.append("")

    # Short-term
    retention_risks = [c for c in classifications if c.get('business_risk') == 'Retention']
    trust_risks = [c for c in classifications if c.get('business_risk') == 'Trust']
    lines.extend([
        "### ðŸ“… Short-Term (1â€“2 Months)",
        "",
        f"- **Reduce retention friction** â€” {len(retention_risks)} tickets indicate retention risk. "
        "Map player journey to identify drop-off points and simplify.",
    ])
    if trust_risks:
        lines.append(f"- **Rebuild trust** â€” {len(trust_risks)} trust-risk tickets. "
                     "Consider a transparent update note or player communication campaign.")
    lines.extend([
        "- **Improve difficulty curve** â€” if balance issues dominate, instrument level telemetry and A/B test adjustments.",
        "- **Enhance positive drivers** â€” double down on features players love (see Positive Drivers section).",
        ""
    ])

    # Long-term
    lines.extend([
        "### ðŸ”­ Long-Term (Quarterly)",
        "",
        "- **Build a real-time feedback loop** â€” move from reactive analysis to proactive monitoring.",
        "- **Segment feedback by payer cohort** â€” payer vs non-payer pain differs and needs separate product responses.",
        "- **Refine AI feedback taxonomy** â€” add game-specific subcategories to improve signal fidelity.",
        "- **Monetization trust investment** â€” ensure IAP flows feel fair, transparent, and rewarding.",
        ""
    ])

    return "\n".join(lines)


def _build_system_critique(classifications: List[Dict[str, Any]]) -> str:
    """Critique the feedback intelligence system itself."""

    total = len(classifications)
    generic = sum(1 for c in classifications if c.get('category') == 'Other')
    low_conf = sum(1 for c in classifications if c.get('confidence', 1) < 0.7)
    no_feature = sum(1 for c in classifications if not c.get('related_feature'))

    lines = [
        _header("ðŸ”¬ Feedback Intelligence System Critique", 2),
        "> How well did the AI analysis actually work? What to improve.\n",
        "| Metric | Value | Assessment |",
        "|--------|-------|------------|",
        f"| Generic 'Other' category usage | {generic} ({round(generic/total*100,1) if total else 0}%) | "
        f"{'ðŸ”´ Too high â€” richer taxonomy needed' if generic > total*0.1 else 'ðŸŸ¢ Acceptable'} |",
        f"| Low-confidence classifications (<0.7) | {low_conf} | "
        f"{'ðŸŸ¡ Review manually' if low_conf > 5 else 'ðŸŸ¢ Good'} |",
        f"| Tickets without feature mapping | {no_feature} | "
        f"{'ðŸŸ¡ Improve feature taxonomy in context' if no_feature > total*0.2 else 'ðŸŸ¢ Good'} |",
        "",
        "**Improvement Recommendations:**",
        "",
        "- Add game-specific categories (e.g., 'Level Difficulty', 'IAP Value', 'Progression Loss') to the AI prompt",
        "- Include player ARPU/payer tier data if available to enable payer-specific analysis",
        "- Track sentiment trends over time (weekly deltas) to detect degradation early",
        "- Add duplicate/near-duplicate detection to avoid skewing frequency counts",
        "- Build a confidence threshold filter â€” tickets below 0.65 confidence should be human-reviewed",
        ""
    ]

    return "\n".join(lines)


def _build_stats_appendix(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]]
) -> str:
    """Compact statistical appendix â€” not the main story."""

    total = insights.total_tickets
    lines = [
        _header("ðŸ“Š Statistical Appendix", 2),
        "> Reference data only â€” the analysis above is what matters.\n",
        "**Category Breakdown:**",
        "",
    ]

    for cat, count in sorted(insights.category_breakdown.items(), key=lambda x: -x[1]):
        pct = round(count / total * 100, 1) if total else 0
        lines.append(f"- {cat}: {count} ({pct}%)")

    lines.extend(["", "**Sentiment Breakdown:**", ""])
    for sent, count in sorted(insights.sentiment_breakdown.items(), key=lambda x: -x[1]):
        pct = round(count / total * 100, 1) if total else 0
        lines.append(f"- {sent}: {count} ({pct}%)")

    lines.extend(["", "**Top Features Mentioned:**", ""])
    for feat, count in sorted(insights.feature_breakdown.items(), key=lambda x: -x[1])[:10]:
        if feat != 'Unspecified':
            pct = round(count / total * 100, 1) if total else 0
            lines.append(f"- {feat}: {count} ({pct}%)")

    lines.append("")
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN REPORT BUILDERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_markdown_report(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]],
    input_params: FeedbackAnalysisInput,
    game_context: Optional[GameFeatureContext] = None
) -> str:
    """
    Generate executive-level Markdown Feedback Intelligence Report.
    """
    logger.info("Generating executive Feedback Intelligence Report...")

    sections = [
        _build_executive_brief(insights, classifications, input_params),
        _build_pain_points(classifications, insights),
        _build_positive_drivers(classifications, insights),
        _build_hidden_patterns(classifications, insights),
        _build_strategic_recommendations(insights, classifications),
        _build_system_critique(classifications),
        _build_stats_appendix(insights, classifications),
        _divider(),
        f"*Report generated by Freshdesk Feedback AI Analysis System â€” "
        f"{datetime.now().strftime('%Y-%m-%d %H:%M')}*\n"
    ]

    logger.info("âœ“ Executive Markdown report generated")
    return "\n".join(sections)


def generate_json_insights(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]],
    input_params: FeedbackAnalysisInput,
    metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """Generate structured JSON insights report."""
    logger.info("Generating JSON insights report...")

    # Business risk summary
    risks = Counter(c.get('business_risk') for c in classifications if c.get('business_risk'))
    severities = Counter(c.get('sentiment_severity') for c in classifications if c.get('sentiment_severity'))
    pain_types = Counter(c.get('pain_type') for c in classifications if c.get('pain_type'))
    payer_signals = Counter(c.get('player_type_signal') for c in classifications if c.get('player_type_signal'))

    json_report = {
        'report_metadata': {
            'game_name': input_params.game_name,
            'platform': input_params.os,
            'analysis_period': {
                'start_date': input_params.start_date,
                'end_date': input_params.end_date
            },
            'generated_at': datetime.now().isoformat(),
            'total_tickets_analyzed': insights.total_tickets,
            'ai_average_confidence': insights.average_confidence
        },
        'business_intelligence': {
            'business_risk_breakdown': dict(risks),
            'sentiment_severity_breakdown': dict(severities),
            'pain_type_breakdown': dict(pain_types),
            'player_type_signals': dict(payer_signals),
            'critical_ticket_count': severities.get('Critical', 0),
            'churn_threat_count': sum(1 for c in classifications if 'Churn' in (c.get('intent') or '')),
            'payer_complaint_count': payer_signals.get('Payer', 0)
        },
        'summary': {
            'total_tickets': insights.total_tickets,
            'category_breakdown': insights.category_breakdown,
            'sentiment_breakdown': insights.sentiment_breakdown,
            'feature_breakdown': insights.feature_breakdown,
            'top_issues': insights.top_issues,
        },
        'patterns': insights.key_patterns,
        'recent_change_impacts': insights.recent_change_impacts,
        'detailed_classifications': classifications,
        'metadata': metadata
    }

    logger.info("âœ“ JSON insights generated")
    return json_report


def save_reports(
    insights: AggregatedInsights,
    classifications: List[Dict[str, Any]],
    input_params: FeedbackAnalysisInput,
    game_context: Optional[GameFeatureContext] = None,
    metadata: Optional[Dict[str, Any]] = None
) -> Dict[str, Path]:
    """Generate and save both Markdown and JSON reports."""
    logger.info("="*70)
    logger.info("Generating Feedback Intelligence Reports")
    logger.info("="*70)

    REPORTS_MARKDOWN_DIR.mkdir(parents=True, exist_ok=True)
    REPORTS_JSON_DIR.mkdir(parents=True, exist_ok=True)

    safe_game_name = sanitize_filename(input_params.game_name)
    timestamp = get_timestamp()

    base_filename = (
        f"{safe_game_name}_{input_params.os}_"
        f"{input_params.start_date}_to_{input_params.end_date}_{timestamp}"
    )

    # Markdown report
    markdown_content = generate_markdown_report(
        insights, classifications, input_params, game_context
    )
    markdown_path = REPORTS_MARKDOWN_DIR / f"report_{base_filename}.md"
    save_markdown(markdown_content, markdown_path)
    logger.info(f"âœ“ Markdown report: {markdown_path.name}")

    # JSON report
    json_insights = generate_json_insights(
        insights, classifications, input_params, metadata or {}
    )
    json_path = REPORTS_JSON_DIR / f"insights_{base_filename}.json"
    save_json(json_insights, json_path)
    logger.info(f"âœ“ JSON insights: {json_path.name}")

    logger.info("="*70)
    logger.info("âœ“ Report generation complete")
    logger.info("="*70)

    return {'markdown': markdown_path, 'json': json_path}
